We build a kernel for CIC modularly, by first developing a kernel for a generic PTS (file \verb+kernel_pts.elpi+) and then extending it with inductive types (file \verb+kernel_inductives.elpi+ that accumulates \verb+kernel_pts.elpi+). In order to use the kernel, ones needs to accumulate it together with another file that implements the PTS rules, like \verb+pts_cc.elpi+ for those of the Calculus of Constructions (CC) or \verb+pts_cc_predicative.elpi+ for those of Luo's ECC.

Terms of a generic PTS are encoded in $\lambda$Prolog in the shallow style of Higher Order Abstract Syntax (also called $\lambda$-tree syntax in~\cite{??}):
\begin{verbatim}
kind term *
type sort universe                       -> term  % sort
type prod (term -> term)                 -> term  % dependent product
type abs  (term -> term)                 -> term  % lambda-abstraction
type appl term -> list term              -> term  % n-ary application
type abbr term -> term -> (term -> term) -> term  % local declaration (let-in)
\end{verbatim}

The kernel for a PTS implements two main judgement: the typing judgement \verb-t+step T U- and the conversion judgement \verb-conv+top T1 M T2-. The former verifies if \verb+T+ is well typed, inferring the type \verb+U+ for \verb+T+. The second, depending on the value of the flag \verb+M+, checks if \verb+T1+ is convertible with \verb+T2+ or if \verb+T1+ is a subtype of \verb+T2+ (up to conversion). The latter judgement is called by the former in order to compare types during type-checking. Auxiliary judgements are used freely in the code, like \verb-has+sort T S- that behaves like \verb-t+step T S- but also checks \verb+S+ to be a sort.

The type-checking rules are all non surprising. For example, two of them are:
\begin{verbatim}
t+step (abst W F1) (prod W F2) :-
  has+sort W _S1,
 pi x\ t+step x W => (t+step (F1 x) (F2 x)).

t+step (sort S1) (sort S2) :- pts+pair S1 S2.
\end{verbatim}

The former rule type-checks $\lambda$-abstractions via dependent products, assuming the PTS to be full. XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
The latter delegates the type-checking of a sort \verb+S1+ to the PTS implementation by calling the \verb-pts+pair S1 S2- predicate, that will be populated in the files that implement the various PTSs.

The rules to check if two terms are convertible are more interesting, because they implement a reduction machine similar to a KAM, but for call-by-need (YYYYYYYYYYYYYY citare papero CSC e Accattoli):
\begin{verbatim}
conv+top T1 M T2 :- conv+main T1 [] M T2 [].

conv+main T1 P1 M T2 P2 :- whd+l+delta T1 P1 (red+whnf T2 P2 M)
\end{verbatim}


====================================================
PER FERRUCCIO: STO LAVORANDO QUI SOPRA, SOTTO E' ROBA TUA
====================================================

A kernel for CIC must define two main relations on CIC terms:
\verb+type_step T U+
asserting that \verb+U+ is an inferred type of \verb+T+,
and \verb+conv U1 U2+ 
asserting that \verb+U1+ and \verb+U2+ are convertible
(we take the name \verb+type_step+ from XXXXXXXXXXXX).

Our prototype achieves this goal by taking advantage of the next features of $\lambda$Prolog.

\begin{itemize}

\item
We can extend the existing predicates on new forms of terms
simply by adding clauses concerning these forms. 
Therefore the kernel's architecture can be modular,
in that a core kernel designed for an arbitrary full pure type system (PTS)
underlies a kernel extension taking care of global constants,
inductive types and recursive definitions.
We define the sort hierarchy of CIC in a separate component of the kernel as well.
This component describes the signature of CIC as a PTS,
and the subsumption relation on CIC sorts.

\item
In CIC, both conversion and type inference occur w.r.t. an environment,
and we can use the implicit environment provided by the
$\lambda$Prolog engine, instead of defining our own environment explicitly.
The environment must maintain the expected type of constants and variables,
as well as their $\delta$-expansion when appropriate.
At the moment, we take the data on global constants from the
environment of the Matita ITP, with which we interface the extended
component of our kernel. XXXXXXXXXX

\end{itemize}

Conversion is asserted by levels by the predicate \verb+conv_whnf U1 U2+,
that expects \verb+U1+ and \verb+U2+ in weak head normal form (WHNF).
Of course a metavariable optionally applied to arguments is a partial
term in WHNF, so an elaborator can introduce unification as a
generalization of conversion, just by extending this specific predicate.

Inference of a type \verb+U+ for \verb+T+ is directed by the syntax of \verb+T+
according to the aforementioned predicate \verb+type_step T U+.
When \verb+T+ is the application of \verb+T0+ to some arguments,
and given \verb+type_step T0 U0+,
we check these arguments against the $\Pi$-abstractions (i.e. the
universal quantifications) arising from \verb+U0+ after reduction to
WHNF by levels. Here, we traverse each quantification by issuing a $\Pi$-reduction
(i.e. the equivalent of a $\beta$-reduction on a $\Pi$).

The responsibility of this check lies with the predicate \verb+whd_pi U0 U+,
by which we compute the outcome \verb+U+ after the quantifications of
\verb+U0+ are traversed. Indeed \verb+U+ is an inferred type for \verb+T+.

If an application has an unknown type \verb+X+,
an elaborator may extend this predicate to guess the quantifications
that must occur in \verb+X+ on the basis of the application's arguments.

The elaborator may as well extend the predicate \verb+type_step T U+
in order to handle the situations in which
the expected type of a metavariable \verb+T+ is known.

Finally, note that we issue both $\beta$-reductions and $\Pi$-reductions
by adding an explicit substitution to the context in which computation occurs.
As we issue this substitution lazily,
our kernel does not need the ``copying'' predicate on terms
(following the terminology of $\lambda$Prolog).
